{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum Likelihood Estimation for CIR process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AlgorithmImports import *\n",
    "import math\n",
    "import scipy.optimize as so\n",
    "import scipy.special as sp\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def loglikelihood(params,*args):\n",
    "    theta,mu,sigma = params\n",
    "    \n",
    "    #if(sigma > np.sqrt(2*mu*theta)):\n",
    "    #   sigma = np.sqrt(2*theta*mu)\n",
    "        \n",
    "    y, dt = args\n",
    "    n = len(y)\n",
    "    \n",
    "    sigma_tilde = np.sqrt(sigma**2*((1 - np.e**(-mu*dt))/(2*mu)))\n",
    "    q = 2*mu*theta/sigma**2 - 1\n",
    "    sum_1 = 0\n",
    "    sum_2 = 0\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        sum_1 += y[i] + y[i - 1]*np.e**(-mu*dt)\n",
    "        sum_2 += q/2*np.log(y[i]/(y[i - 1]*np.e**(-mu*dt))) + np.log(sp.iv(q,2*np.sqrt(y[i]*y[i - 1]*np.e**(-mu*dt))/sigma_tilde**2))\n",
    "\n",
    "    \n",
    "    log_likelihood = -2*np.log(sigma_tilde) - 1/(n*sigma_tilde**2)*sum_1 + (1/n)*sum_2\n",
    "    \n",
    "    return -log_likelihood\n",
    "\n",
    "def estimate_coefficients(y, dt):\n",
    "    \n",
    "   # theta ∈ ℝ, mu > 0, sigma > 0\n",
    "                                                           # we need 1e-10 b/c scipy bounds are inclusive of 0, \n",
    "                                                          # and sigma = 0 causes division by 0 error\n",
    "    \n",
    "    #y_t = np.diff(y)/np.sqrt(y[0:len(y) - 1])\n",
    "    #x_1 = dt/np.sqrt(y[0:len(y) - 1])\n",
    "    #x_2 = np.sqrt(y[0:len(y) - 1])\n",
    "    #df = pd.DataFrame({'y' : y, 'x_1' : x_1, 'x_2' : x_2})\n",
    "    #model = sm.OLS(df['y'],df[['x_1','x_2']])\n",
    "    #mu_init = -model.fit.params[1]\n",
    "    #theta_init = -model.fit.params[0]/model.fit.params[1]\n",
    "    #sigma_init = model.fit.resid.std()\n",
    "    #print(mu_init,theta_init,sigma_init)\n",
    "    N = len(y)\n",
    "  \n",
    "    theta_init = np.mean(y)\n",
    "    initial_guess = (theta_init, 100, 100)\n",
    "    bounds = ((1e-5, None), (1e-5, None), (1e-5, None))\n",
    "      # initial guesses for theta, mu, sigma\n",
    "    result = so.minimize(loglikelihood, initial_guess, args=(y,dt), bounds=bounds)\n",
    "    theta, mu, sigma = result.x \n",
    "    \n",
    "    return theta, mu, sigma, result.fun\n",
    "\n",
    "# From QuantConnect.com\n",
    "\n",
    "def compute_portfolio_values(ts_A, ts_B, alloc_B):\n",
    "        ts_A = ts_A / ts_A[0]\n",
    "        ts_B = ts_B / ts_B[0]\n",
    "        return ts_A - alloc_B * ts_B\n",
    "\n",
    "def argmax_B_alloc(ts_A, ts_B,dt):\n",
    "        \n",
    "        theta = mu = sigma = alloc_B = 0\n",
    "        max_log_likelihood = 0\n",
    "\n",
    "        def compute_coefficients(x):\n",
    "            portfolio_values = compute_portfolio_values(ts_A, ts_B, x)\n",
    "            return estimate_coefficients(portfolio_values,dt)\n",
    "        \n",
    "        vectorized = np.vectorize(compute_coefficients)\n",
    "        linspace = np.linspace(.001, 1, 100)\n",
    "        res = vectorized(linspace)\n",
    "        index = res[3].argmax()\n",
    "\n",
    "        return res[0][index], res[1][index], res[2][index], linspace[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pymle.models import CIR\n",
    "import pymle.models.OrnsteinUhlenbeck as OU\n",
    "from pymle.core.TransitionDensity import ExactDensity, KesslerDensity\n",
    "from pymle.fit.AnalyticalMLE import AnalyticalMLE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gld = yf.download('GC=F', start='2020-01-01', end='2022-12-31', progress=False)\n",
    "crude = yf.download('CL=F', start='2020-01-01', end='2022-12-31', progress=False)\n",
    "silver = yf.download('SI=F', start='2020-01-01', end='2022-12-31',progress=False)\n",
    "copper = yf.download('HG=F', start='2020-01-01', end='2022-12-31', progress=False)\n",
    "palladium = yf.download('PA=F', start='2020-01-01', end='2022-12-31', progress=False)\n",
    "platinum = yf.download('PL=F', start='2020-01-01', end='2022-12-31', progress=False)\n",
    "#corn = yf.download('C=F', start='2020-01-01', end='2022-12-31', progress=False)\n",
    "ts = compute_portfolio_values(gld['Adj Close'], crude['Adj Close'], 1)\n",
    "\n",
    "\n",
    "def check_stationarity(timeseries):\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "check_stationarity(ts)\n",
    "\n",
    " # ===========================\n",
    " # Set the true model (CIR) params, to simulate the process\n",
    " # ===========================\n",
    " # ===========================\n",
    " # Fit maximum Likelihood estimators\n",
    " # ===========================\n",
    " # Choose some initial guess for params fit\n",
    "param_bounds = [(0.0001, 1), (0.0001, 30), (0.0001, 1)]\n",
    "goldCrudeModelsCIR = []\n",
    "goldCrudeModelsOU = []\n",
    " #silverCrudeModels = []\n",
    " #goldSilverModels = []\n",
    " #copperCrudeModels = []\n",
    "dt = 1/len(gld)\n",
    " # Choose some initial guess for params fit\n",
    "for i in np.linspace(.001, 0.5, 100):\n",
    "    model = CIR()\n",
    "    model2 = OU()\n",
    "    goldCrude = compute_portfolio_values(gld['Close'], crude['Close'], i)\n",
    "    guess = np.array([0.5, np.mean(goldCrude), 0.10])\n",
    "    #silverCrude = compute_portfolio_values(silver['Close'], crude['Close'], i)\n",
    "    #goldSilver = compute_portfolio_values(gld['Close'], silver['Close'], i)\n",
    "    #copperCrude = compute_portfolio_values(copper['Close'], crude['Close'], i)\n",
    "    exact_est = AnalyticalMLE(goldCrude, param_bounds, dt, density=ExactDensity(model)).estimate_params(guess)\n",
    "    goldCrudeModelsCIR.append(exact_est)\n",
    "    exact_est2 = AnalyticalMLE(goldCrude, param_bounds, dt, density=ExactDensity(model2)).estimate_params(guess)\n",
    "    goldCrudeModelsOU.append(exact_est2)\n",
    "    #exact_est = AnalyticalMLE(silverCrude, param_bounds, dt,density=ExactDensity(model)).estimate_params(guess)\n",
    "    #silverCrudeModels.append(exact_est)\n",
    "    #exact_est = AnalyticalMLE(goldSilver, param_bounds, dt,density=ExactDensity(model)).estimate_params(guess)\n",
    "    #goldSilverModels.append(exact_est)\n",
    "    #exact_est = AnalyticalMLE(copperCrude, param_bounds, dt, density=ExactDensity(model)).estimate_params(guess)\n",
    "    #copperCrudeModels.append(exact_est)\n",
    "\n",
    "log_likelihoods = [goldCrudeModelsCIR[i].log_like for i in range(len(goldCrudeModelsCIR))]\n",
    "plt.plot(np.linspace(.001, 0.5, 100), log_likelihoods)\n",
    "plt.show()\n",
    "print(\"optimal parameters are: \", goldCrudeModelsCIR[np.argmax(log_likelihoods)].params)\n",
    "print(\"optimal B is: \", np.linspace(.001, 0.5, 100)[np.argmax(log_likelihoods)])\n",
    "log_likelihoods = [goldCrudeModelsOU[i].log_like for i in range(len(goldCrudeModelsOU))]\n",
    "plt.plot(np.linspace(.001, 0.5, 100), log_likelihoods)\n",
    "plt.show()\n",
    "print(\"optimal parameters are: \", goldCrudeModelsOU[np.argmax(log_likelihoods)].params)\n",
    "print(\"optimal B is: \", np.linspace(.001, 0.5, 100)[np.argmax(log_likelihoods)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AlgorithmImports import *\n",
    "import math\n",
    "import scipy.optimize as sci\n",
    "import numpy as np\n",
    "import mpmath\n",
    "\n",
    "def V_X(y, theta, mu, sigma, r,c):\n",
    "    b_star = compute_b_star(mu,theta,sigma,r)\n",
    "    if y >= 0 and y < b_star:\n",
    "        return (b_star- c)/F_X(b_star,theta, mu, sigma, r,c)*F_X(y,theta, mu, sigma, r,c)\n",
    "    else:\n",
    "        return y - c\n",
    "    \n",
    "def dV_X(y,theta, mu, sigma, r,c):\n",
    "    b_star = compute_b_star(mu,theta,sigma,r)\n",
    "    if y >= 0 and y < b_star:\n",
    "        return (b_star- c)/F_X(b_star,theta, mu, sigma, r,c)*dF_X(y,theta, mu, sigma, r,c)\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    " # Theorem 4.4\n",
    "def J_X(y,theta, mu, sigma, r,c):\n",
    "    d_star = compute_d_star(mu,theta,sigma,r)\n",
    "    if y >= 0 and y < d_star:\n",
    "        return V_X(y,theta, mu, sigma, r,c)- (y + c)\n",
    "    else:\n",
    "        return (V_X(d_star,theta, mu, sigma, r,c)- (d_star + c))/G_X(d_star,theta, mu, sigma, r,c)*G_X(y,theta, mu, sigma, r,c)\n",
    " # 4.9\n",
    "def F_X(y,mu,theta,sigma,r):\n",
    "    a,b,z = r/mu,(2*mu*theta)/sigma**2,(2*mu*y)/sigma**2\n",
    "    return mpmath.hyp1f1(a,b,z)\n",
    "\n",
    "def dF_X(y,mu,theta,sigma,r):\n",
    "    a,b,z = r/mu,(2*mu*theta)/sigma**2,(2*mu*y)/sigma**2\n",
    "    return a/b*mpmath.hyp1f1(a,b,z)\n",
    "\n",
    " # 4.9\n",
    "def G_X(y,mu,theta,sigma,r):\n",
    "    a,b,z = r/mu,(2*mu*theta)/sigma**2,(2*mu*y)/sigma**2\n",
    "    return mpmath.gamma(1- b)/mpmath.gamma(a- b + 1)*mpmath.hyp1f1(a,b,z) + mpmath.gamma(b- 1)/mpmath.gamma(a)*z**(1- b)*mpmath.hyp1f1(a- b + 1,2-b,z)\n",
    "\n",
    "def dG_X(y,mu,theta,sigma,r):\n",
    "    a,b,z = r/mu,(2*mu*theta)/sigma**2,(2*mu*y)/sigma**2\n",
    "    return-a*(mpmath.gamma(1- b)/mpmath.gamma(a- b + 1)*mpmath.hyp1f1(a,b,z) + mpmath.gamma(b- 1)/mpmath.gamma(a)*z**(1- b)*mpmath.hyp1f1(a- b + 1,2-b,z))\n",
    "\n",
    "#def y_b(y):\n",
    "    #return (self.mu*self.theta- self.r*self.c_b)/(self.mu + self.r)\n",
    "#def y_s(y):\n",
    " #\n",
    "    #return (self.mu*self.theta + self.r*self.c_s)/(self.mu + self.r)\n",
    "\n",
    "def compute_b_star(mu,theta,sigma,r):\n",
    "    def f(y):\n",
    "        return F_X(y,mu,theta,sigma,r)- (y)*dF_X(y,mu,theta,sigma,r)\n",
    "    return sci.brentq(f, 0, 1)\n",
    "def compute_d_star(mu,theta,sigma,r):\n",
    "    def g(y):\n",
    "        return G_X(y,mu,theta,sigma,r)(dV_X(y,mu,theta,sigma,r,r)- 1)- dG_X(y,mu,theta,sigma,r)(V_X(y,mu,theta,sigma,r,r)- y)\n",
    "    return sci.brentq(g, 0, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
